{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tiktoken \n",
    "from typing import Union, List\n",
    "from dotenv import load_dotenv\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA, LLMChain\n",
    "from langchain import OpenAI, PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import tool\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import AgentAction, AgentFinish\n",
    "from langchain.tools import Tool\n",
    "from langchain.tools.render import render_text_description\n",
    "from langchain.agents.output_parsers import ReActSingleInputOutputParser\n",
    "from langchain.agents.format_scratchpad import format_log_to_str\n",
    "from tools.callbacks import AgentCallbackHandler\n",
    "\n",
    "#load variable from .env\n",
    "load_dotenv()  \n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(file_path=pdf_path)\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=30, separator=\"\\n\")\n",
    "chunked_docs = text_splitter.split_documents(documents=documents)\n",
    "\n",
    "# Count the chunks\n",
    "num_chunks = len(chunked_docs)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstores = FAISS.from_documents(chunked_docs, embeddings)\n",
    "vectorstores.save_local(\"damac_database\")\n",
    "\n",
    "damac_vectorstore = FAISS.load_local(\"damac_database\", embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can you summarize this agreement document for me?\n"
     ]
    }
   ],
   "source": [
    "#assign variables\n",
    "Question = \"\"\"\n",
    "        can you summarized this agrement document for me\n",
    "        \"\"\"\n",
    "input_language = 'TH'\n",
    "output_language = 'EN'\n",
    "\n",
    "#promptTemplate\n",
    "summary_templates = \"\"\"\n",
    "    You are a translator specilist who have experinces of 35 years of translating from {input_language} language to {output_language}\n",
    "    given the question {Question} you are task to translate the language to {output_language}, if the question is in {output_language} \n",
    "    keep the question as is.\n",
    "    Caution!\n",
    "    1. Only provide me the answer with no explanation\n",
    "    \"\"\"\n",
    "\n",
    "summary_prompts_template = PromptTemplate(input_variables=['Question','input_language','output_language'], template = summary_templates)\n",
    "\n",
    "llm = ChatOpenAI(temperature= 0, model_name=\"gpt-4\",api_key=openai_api_key)\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=summary_prompts_template) \n",
    "\n",
    "Question = chain.run(Question=Question,input_language=input_language,output_language=output_language)\n",
    "\n",
    "print(Question)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! stop is not default parameter.\n",
      "                    stop was transferred to model_kwargs.\n",
      "                    Please confirm that stop is what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This is a lease agreement between Supsumphan Co., Ltd. (the Lessor) and Daria Data Centre and Cloud Services Co., Ltd. (the Lessee) for a period of 2 years. The agreement prohibits the establishment of a partnership or agency between the Parties and states that any waiver or modification must be made in writing. It also states that this agreement supersedes any prior agreements or understandings between the Parties. The Lessor is the legal owner of the Land for which the lease is being agreed upon. \n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def get_ans_damac(Question: str) -> str:\n",
    "    \"\"\"Returns the answer based on the question related to Agreement\"\"\"\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    damac_vectorstore = FAISS.load_local(\"damac_database\", embeddings)\n",
    "    qa = RetrievalQA.from_chain_type(\n",
    "    llm=OpenAI(), chain_type=\"stuff\", retriever=damac_vectorstore.as_retriever(),\n",
    "    )\n",
    "    result = qa.run(Question)\n",
    "    return result\n",
    "\n",
    "@tool\n",
    "def get_ans_elon(Question: str) -> str:\n",
    "    \"\"\"Returns the answer based on the question related to ELONMUSK\"\"\"\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    elonmusk_vectorstore = FAISS.load_local(\"elonmusk_database\", embeddings)\n",
    "    qa = RetrievalQA.from_chain_type(\n",
    "    llm=OpenAI(), chain_type=\"stuff\", retriever=elonmusk_vectorstore.as_retriever(),\n",
    "    )\n",
    "    result = qa.run(Question)\n",
    "    return result\n",
    "\n",
    "def find_tool_by_name(tools: List[Tool], tool_name: str) -> Tool:\n",
    "    for tool in tools:\n",
    "        if tool.name == tool_name:\n",
    "            return tool\n",
    "    raise ValueError(f\"Tool wtih name {tool_name} not found\")\n",
    "\n",
    "\n",
    "tools = [get_ans_damac, get_ans_elon]\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template=template).partial(\n",
    "    tools=render_text_description(tools),\n",
    "    tool_names=\", \".join([t.name for t in tools]),\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=1, \n",
    "    stop=[\"\\nObservation\"], \n",
    "    model = \"gpt-4\",\n",
    "    api_key=openai_api_key,\n",
    ")\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | ReActSingleInputOutputParser()\n",
    ")\n",
    "\n",
    "\n",
    "agent_step: Union[AgentAction, AgentFinish] = agent.invoke(\n",
    "            {\"input\": Question}\n",
    "        )\n",
    "\n",
    "if isinstance(agent_step, AgentAction):\n",
    "            tool_name = agent_step.tool\n",
    "            tool_to_use = find_tool_by_name(tools, tool_name)\n",
    "            tool_input = agent_step.tool_input\n",
    "\n",
    "Observation = tool_to_use.func((str(tool_input)))\n",
    "\n",
    "print(Observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "นี่คือข้อตกลงส่วนตัวและเป็นความลับระหว่างผู้ให้เช่า ซึ่งเป็นบริษัท SUPSUMPHAN CO., LTD., และผู้เช่าที่เป็นผู้ให้บริการโครงสร้างพื้นฐานดิจิตอลและศูนย์ข้อมูล ข้อตกลงระบุว่าผู้เช่าจะเช่าที่ดินในเขตห้วยขวาง กรุงเทพมหานครเป็นระยะเวลา 2 ปี ข้อตกลงยังรวมถึงข้อกำหนดเกี่ยวกับการแก้ไข ความสัมพันธ์ทางธุรกิจ และการสละสิทธิ์ ข้อตกลงนี้ทำหน้าที่เป็นความเข้าใจร่วมกันทั้งหมดระหว่างสองฝ่ายและแทนข้อตกลงก่อนหน้านี้ทั้งหมด\n"
     ]
    }
   ],
   "source": [
    "#assign varible\n",
    "output = Observation\n",
    "\n",
    "#promptTemplate\n",
    "summary_templates = \"\"\"\n",
    "    You are a translator specilist who have experinces of 35 years of translating from {input_language} language to {output_language}\n",
    "    given the information {output} you are task to translate the language to {input_language}.\n",
    "    Caution!\n",
    "    Only provide me the answer with no explanation\n",
    "    \"\"\"\n",
    "\n",
    "summary_prompts_template = PromptTemplate(input_variables=['output','input_language','output_language'], template = summary_templates)\n",
    "\n",
    "llm = ChatOpenAI(temperature= 2, model_name=\"gpt-4\",api_key=openai_api_key)\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=summary_prompts_template) \n",
    "\n",
    "Output = chain.run(output=output,input_language=input_language,output_language=output_language)\n",
    "\n",
    "print(Output)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
